# åŸºç¡€è·¯å¾„
base_dir: "./"
data_dir: "./data"
checkpoint_dir: "./checkpoints"

# è®¾å¤‡é…ç½®
device: "cuda"
distributed: False

# æ•°æ®é›†é…ç½®
# dataset01
#dataset:
#  train:
#    json_file: "/home/cxx/Code/kalibr/TwoHandDataset/hands_coco.json"
#    img_dir: "/home/cxx/Code/kalibr/TwoHandDataset"
#    transform: None
#  val:
#    json_file: "/home/cxx/Code/kalibr/output_frames_1/hands_coco.json"
#    img_dir: "/home/cxx/Code/kalibr/output_frames_1"
#    transform: None
dataset:
  train:
    - json_file: "/home/cxx/Code/kalibr/TwoHandDataset/hands_coco.json"
      img_dir: "/home/cxx/Code/kalibr/TwoHandDataset"
    - json_file: "/home/cxx/Code/kalibr/TwoHandDataset_low_occlusion/hands_coco.json"
      img_dir: "/home/cxx/Code/kalibr/TwoHandDataset_low_occlusion"
#    transform: None
  val:
    - json_file: "/home/cxx/Code/kalibr/output_frames_1/hands_coco.json"
      img_dir: "/home/cxx/Code/kalibr/output_frames_1"
    - json_file: "/home/cxx/Code/kalibr/TwoHandDataset_low_occlusion/hands_coco.json"
      img_dir: "/home/cxx/Code/kalibr/TwoHandDataset_low_occlusion"
#    transform: None

dataset_name: "HandPose"
input_views: 2
# dataset Lighthand99k
#dataset:
#  train:
#    json_file: "/data2/LightHand99K/LightHand/evaluation/annotations.json"
#    img_dir: "/data2/LightHand99K/LightHand/evaluation"
#    transform: False
#  val:
#    json_file: "/data2/LightHand99K/LightHand/evaluation/annotations.json"
#    img_dir: "/data2/LightHand99K/LightHand/evaluation"
#    transform: False


# æ•°æ®é¢„å¤„ç†
# # æ•°æ®å¢å¼º
transform:
  normalize: True
data_preprocessor:
  mean: [123.675, 116.28, 103.53]  # å½’ä¸€åŒ–å‡å€¼ (ImageNet å‡å€¼)
  std: [58.395, 57.12, 57.375]  # å½’ä¸€åŒ–æ ‡å‡†å·®
  bgr_to_rgb: True  # OpenCV è¯»å–çš„é»˜è®¤æ˜¯ BGRï¼Œéœ€è¦è½¬æ¢æˆ RGB


train_pipeline:
#  - type: "LoadImage"
  - type: "GetBBoxCenterScale"
    padding: 1.25
  - type: "TopdownAffine"
    input_size: [256, 256]
  - type: "Resize"
    target_size: [256, 256]
  - type: "RandomFlip" # Random horizontal flip
    prob: 0.2
  - type: "RandomRotation"
    angle_range: [-5, 5]
  - type: "GenerateTarget"  # Need put it in the last pipeline
    name: 'HandPoseCodec'
    image_size: [256,256]
    heatmap_size: [64,64,64]
    heatmap3d_depth_bound: 300.0
    root_depth_bound: 300.0
    sigma: 0.05
    max_bound: 1.0

val_pipeline:
#  - type: "GetBBoxCenterScale"
#    padding: 1.25
#  - type: "TopdownAffine"
#    input_size: [ 256, 256 ]
  - type: "Resize"
    target_size: [256, 256]
  - type: "GenerateTarget"  # Need put it in the last pipeline
    name: 'HandPoseCodec'
    image_size: [256,256]
    heatmap_size: [64,64,64]
    heatmap3d_depth_bound: 300.0
    root_depth_bound: 300.0
    sigma: 0.05  #  ğœå¤ªå°ï¼ˆæ¯”å¦‚ 1 æˆ–æ›´å°ï¼‰ï¼Œé«˜æ–¯æ ¸ä¼šéå¸¸å°–é”ï¼Œå¤§éƒ¨åˆ†å€¼æ¥è¿‘ 0ï¼Œåªæœ‰æå°‘ç½‘æ ¼æ˜¯ 1ï¼›ç½‘ç»œåœ¨å­¦ä¹ æ—¶å¯èƒ½æ¢¯åº¦ç¨€ç–ï¼Œéš¾ä»¥å­¦åˆ°å¹³æ»‘åˆ†å¸ƒã€‚
    max_bound: 1.0

  # - type: "PackPoseInputs"
  #   meta_keys: ["img_id", "img_path", "input_size", "center", "scale", "hand_type", "hand_type_valid", "rel_root_depth"]

# æ¨¡å‹é…ç½®
model:
  backbone_config:
    backbone: "ResNet_SKACOT"  # é€‰æ‹© ResNet å˜ä½“
    in_channels: 3  # è¾“å…¥channel , when use model06 structure need set in_channels==3 , and real data input is 6
    resnet_depth: 18  # é€‰æ‹© ResNet æ·±åº¦ {18, 34, 50, 101, 152}
    channels: 512 # resnetçš„æœ€åçš„è¾“å‡ºç‰¹å¾å¤§å°
    out_channels: 512 # æœ€åæ•´ä¸ªæ¨¡å‹æƒ³è¦çš„è¾“å‡ºå¤§å°
  neck: "GAP"  # é€‰æ‹© Neck ç»“æ„ {GAP, FPN, SimpleConv, DeformableConv, Hourglass}
  neck_config:
    in_channels: 512  # ResNet æœ€ç»ˆè¾“å‡ºçš„é€šé“æ•°  ï¼ŒGAP çš„æ—¶å€™ä¸éœ€è¦
  head_config:
    in_channels: 512
    num_joints: 21 
    depth_size: 64
    heatmap_size: [64,64,64]


# è®­ç»ƒè¶…å‚æ•°
train:
  gpu: [0,1,2]
  batch_size: 60
  epochs: 100
  learning_rate: 0.0001
  weight_decay: 0.1
  optimizer: "adam"
  scheduler: "step"
  step_size: 30
  gamma: 0.5
  num_workers: 10
  pin_memory: True
  resume: "./work_dir/config_HandPose_TwoInput_res18_model06_04_22/checkpoints/best_model.pth"

  visualization_interval: 100  # æ¯10ä¸ªè¿­ä»£ä¿å­˜ä¸€æ¬¡å¯è§†åŒ–ç»“æœ
  visualization_save_path: "./vis_results_with_TwoInput" # ä¿å­˜è·¯å¾„

# è¯„ä¼°å’Œæµ‹è¯•
test:
  batch_size: 20
  flip_test: False

# å¯è§†åŒ–é…ç½®
visualization:
  save_images: True
  save_path: "./vis_results"
