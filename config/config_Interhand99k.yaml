# åŸºç¡€è·¯å¾„
base_dir: "./"
data_dir: "./data"
checkpoint_dir: "./checkpoints"

# è®¾å¤‡é…ç½®
device: "cuda"
distributed: False

# æ•°æ®é›†é…ç½®
# dataset01

dataset_name: "Interhand99k"  # Interhand99k, HandPose

dataset:
  train:
    json_file: "/data1/LightHand/evaluation/annotations_coco.json"
    img_dir: "/data1/LightHand/evaluation"
    transform: False
  val:
    json_file: "/data1/LightHand/evaluation/annotations_coco.json"
    img_dir: "/data1/LightHand/evaluation"
    transform: False


# æ•°æ®é¢„å¤„ç†
# # æ•°æ®å¢å¼º
transform:
  normalize: True
data_preprocessor:
  mean: [123.675, 116.28, 103.53]  # å½’ä¸€åŒ–å‡å€¼ (ImageNet å‡å€¼)
  std: [58.395, 57.12, 57.375]  # å½’ä¸€åŒ–æ ‡å‡†å·®
  bgr_to_rgb: True  # OpenCV è¯»å–çš„é»˜è®¤æ˜¯ BGRï¼Œéœ€è¦è½¬æ¢æˆ RGB


train_pipeline:
#  - type: "LoadImage"
  - type: "Resize"
    target_size: [ 256, 256 ]
  - type: "GetBBoxCenterScale"
    padding: 1.25
  - type: "TopdownAffine"
    input_size: [256, 256]
  - type: "RandomFlip" # Random horizontal flip
    prob: 0.5
  - type: "RandomRotation"
    angle_range: [-45, 45]
  - type: "GenerateTarget"  # Need put it in the last pipeline
    name: 'HandPoseCodec'
    image_size: [256,256]
    heatmap_size: [64,64,64]
    heatmap3d_depth_bound: 1000.0
    root_depth_bound: 300.0
#    sigma: 2.5 # è¿™é‡Œä½¿ç”¨åƒç´ çº§åˆ«çš„heatmapç”Ÿæˆçš„æ—¶å€™ä½¿ç”¨çš„
    sigma: 0.05   # è¿™é‡Œä½¿ç”¨çš„æ˜¯æ¯”ç‡å½¢å¼çš„ 0.05 è¡¨ç¤ºçƒ­å›¾é¢ç§¯å æ®5%çš„æ¯”ç‡
    max_bound: 300

val_pipeline:
  - type: "Resize"
    target_size: [256, 256]
  - type: "GenerateTarget"  # Need put it in the last pipeline
    name: 'HandPoseCodec'
    image_size: [256,256]
    heatmap_size: [64,64,64]
    heatmap3d_depth_bound: 1000.0
    root_depth_bound: 300.0
#    sigma: 2.5  #  ğœå¤ªå°ï¼ˆæ¯”å¦‚ 1 æˆ–æ›´å°ï¼‰ï¼Œé«˜æ–¯æ ¸ä¼šéå¸¸å°–é”ï¼Œå¤§éƒ¨åˆ†å€¼æ¥è¿‘ 0ï¼Œåªæœ‰æå°‘ç½‘æ ¼æ˜¯ 1ï¼›ç½‘ç»œåœ¨å­¦ä¹ æ—¶å¯èƒ½æ¢¯åº¦ç¨€ç–ï¼Œéš¾ä»¥å­¦åˆ°å¹³æ»‘åˆ†å¸ƒã€‚
    sigma: 0.02
    max_bound: 1

  # - type: "PackPoseInputs"
  #   meta_keys: ["img_id", "img_path", "input_size", "center", "scale", "hand_type", "hand_type_valid", "rel_root_depth"]

# æ¨¡å‹é…ç½®
model:
  backbone_config:
    backbone: "ResNet_SKACOT"  # é€‰æ‹© ResNet å˜ä½“
    in_channels: 3  # è¾“å‡ºchannel
    resnet_depth: 50  # é€‰æ‹© ResNet æ·±åº¦ {18, 34, 50, 101, 152}
    channels: 2048 # resnetçš„æœ€åçš„è¾“å‡ºç‰¹å¾å¤§å°
    out_channels: 2048 # æœ€åæ•´ä¸ªæ¨¡å‹æƒ³è¦çš„è¾“å‡ºå¤§å°
  neck: "GAP"  # é€‰æ‹© Neck ç»“æ„ {GAP, FPN, SimpleConv, DeformableConv, Hourglass}
  neck_config:
    in_channels: 512  # ResNet æœ€ç»ˆè¾“å‡ºçš„é€šé“æ•°  ï¼ŒGAP çš„æ—¶å€™ä¸éœ€è¦
  head_config:
    in_channels: 2048
    num_joints: 21 
    depth_size: 64
    heatmap_size: [64,64,64]


# è®­ç»ƒè¶…å‚æ•°
train:
  gpu: [0,1,2]
  batch_size: 60
  epochs: 100
  learning_rate: 0.001
  weight_decay: 0.1
  optimizer: "adam"
  scheduler: "step"
  step_size: 20
  gamma: 0.5
  num_workers: 10
  pin_memory: True
  resume: "./checkpoints/best_model.pth"

  visualization_interval: 20  # æ¯10ä¸ªè¿­ä»£ä¿å­˜ä¸€æ¬¡å¯è§†åŒ–ç»“æœ
  visualization_save_path: "./vis_results_Interhand99K_20250325-1" # ä¿å­˜è·¯å¾„

# è¯„ä¼°å’Œæµ‹è¯•
test:
  batch_size: 2
  flip_test: False

# å¯è§†åŒ–é…ç½®
visualization:
  save_images: True
  save_path: "./vis_results_Interhand99K"
